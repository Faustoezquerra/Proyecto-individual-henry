{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Introduction to Exploratory Data Analysis (EDA)\n",
    "\n",
    "To share my understanding of the concept and techniques I know, I’ll take an example of House Prices dataset which is available on Kaggle and try to catch hold of as many insights from the data set using EDA.\n",
    "\n",
    "Here is a quick overview of the things that you are going to learn in this article:\n",
    "\n",
    "Descriptive Statistics\n",
    "Outlier Treatment\n",
    "Grouping of Data\n",
    "Handling missing values in dataset\n",
    "Correlation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats \n",
    "Descriptive Statistics\n",
    "Descriptive Statistics helps to describe the basic features of dataset and obtain summary of the data also know as 5 point summary.\n",
    "\n",
    "Median: The middle value in the Columns , also called 50th percentile. or 2nd quartile.\n",
    "1st Quartile: The 25th percentile.\n",
    "3rd Quartile: The 75th percentile.\n",
    "Minimum : The smallest observation in columns.\n",
    "Maximum: The Largest Observation in columns.\n",
    "The describe method in Pandas helps us to have summary of the dataset for all numerical columns excluding NaN(Not-a-Number or missing ) values.\n",
    "\n",
    "# gives include='all' gives additional summary of the data\n",
    "df.describe(include=’all’) \n",
    "\n",
    ".describe() in pandas helps us to get brief overview of the data. For eg. we can observe that LotFrontage has 1460 values in it which means there is no null value in this variable and mean value is 70 and 50th percentile at 69.0 we can also conclude the there is a slight skewness in the variable to verify this one can also use .skew() method in Pandas.\n",
    "\n",
    "Univariate Analysis Plots\n",
    "Plots which can be used for numeric variable analysis\n",
    "\n",
    "Histogram\n",
    "KDEplot (kernel density estimate)\n",
    "Distplot\n",
    "Boxplot\n",
    "Violin plot\n",
    "Plots which can be used for categorical variable analysis\n",
    "\n",
    "Barchart\n",
    "Piechart\n",
    "Box Plot\n",
    "A boxplot is a standardized way of displaying the distributions of the data based of five point summary. It can tell you about outliers and what their values are. It also gives the idea about the skewness of the data.\n",
    "\n",
    "\n",
    "BoxPLot\n",
    "The upper and lower Quartiles represents the 75th and 25th percentile of the data.\n",
    "\n",
    "sns.boxplot(x='GarageQual',y=‘SalePrice’,data=df)\n",
    "plt.show()\n",
    "\n",
    "We can observe that house with TA have multiple outliers, houses with poor GarageQuality have a price range of $100,000 to $150,000 approx , houses with with Ex are selling for more than $150,000 to $450,000. it tells us that avergae price of Good Garage Quality will cost somewhere around $250,000.\n",
    "\n",
    "Violin plot\n",
    "Violin plots is a method of plotting numeric data and can be considered a combination of the box plot with a kernel density plot. In the violin plot, we can find the same data as in the box plots\n",
    "\n",
    "The advantage of the violin plot over the box plot is that aside from showing the statistics it also shows the entire distribution of the data. This is of interest, especially when dealing with multimodal data, i.e., a distribution with more than one peak.\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.violinplot(x='KitchenQual','SalePrice',hue='CentralAir',data=df,split=True)\n",
    "plt.show()\n",
    "\n",
    "We can make a inference that most of the houses in GD category are priced at $200,000 which are having Central Air , housing not having Central Air are sold for sell than $180,000 approx. , this phenomenon can be observed in every other category of Kitchen Quality.\n",
    "\n",
    "Outlier Treatment\n",
    "An outlier is a data point in a data set that is distant from all other observations. A data point that lies outside the general distribution of the dataset.\n",
    "\n",
    "Formula for Z score = (Observation — Mean)/Standard Deviation\n",
    "\n",
    "\n",
    "Z score\n",
    "Finding 1st quartile and 3rd quartile\n",
    "q1, q3= np.percentile(dataset,[25,75])\n",
    "Find the IQR which is the difference between 3rd and 1st quartile\n",
    "iqr = q3 - q1\n",
    "Find lower and upper bound\n",
    "lower_bound = q1 -(1.5 * iqr) \n",
    "upper_bound = q3 +(1.5 * iqr)\n",
    "We will use z_score for the treatment of outliers.\n",
    "\n",
    "Z-scores may be positive or negative, with a positive value indicating the score is above the mean and a negative score indicating it is below the mean.\n",
    "Any value which is above +3 sd (Standard deviations) and -3 sd is considered as outlier.\n",
    "\n",
    "Detect Outlier (z_score)\n",
    "df['Zscore_SalePrice'] = stats.zscore(df['SalePrice'])\n",
    "df[(df['Zscore_SalePrice'] < -3) | (df['Zscore_SalePrice'] > 3)]\n",
    "The ouput will show 298 rows and 10 columns\n",
    "\n",
    "Remove Outlier\n",
    "df[(df['Zscore_SalePrice'] > -3) & (df['Zscore_SalePrice'] < 3)]\n",
    "For the purpose of demonstration we will remove these outliers from the dataset, and do further analysis on our new dataset.\n",
    "\n",
    "Scatter Plots\n",
    "A scatter plot represents association betweeen two variables, if the variables tends to increase or decrease together the association is said to be posivitive. If one variable increase and other decrease it is said to have negative relation.If there is no pattern the relation is zero.\n",
    "\n",
    "sns.scatterplot( df['column_n'] , df['column_n'] )\n",
    "\n",
    "# Hue- 'Grouping variable that will produce points with different colors. Can be either categorical or numeric, although color mapping will behave differently in latter case.'\n",
    "sns.scatterplot(df['GarageArea'],df['SalePrice'],hue=df['Foundation'])\n",
    "\n",
    "Scatterplot wrt to GarageArea\n",
    "We can observe that price of houses depends upon the size of Garage Area they have but not that much on Foundation. From the above graph we can also conclude there is a linear relationship between GarageArea and SalePrice of house , houses with bigger garage sells for more compared to houses with wither no garage or small garage area.\n",
    "\n",
    "Grouping of Data\n",
    "Assume we want to know the average price of apartment which has Garage,Central Air Conditioner and observe how SalePrice differ from each other. A nice way to do this would be to group data according to SalePrice and GarageType , CentralAir.\n",
    "\n",
    "df.groupby([‘GarageType’,’CentralAir’])[‘SalePrice’].mean()\n",
    "\n",
    "From this output we can clearly see that apartment having Central Air is more expensive than the apartment not having.\n",
    "\n",
    "We can also visualise this in form of bar graph\n",
    "\n",
    "df.groupby(['GarageType','CentralAir'])['SalePrice'].mean().unstack(1).plot.barh()\n",
    "\n",
    "Bar plot wrt to SalePrice\n",
    "Handling missing values\n",
    "Missing values are those rows or columns which have no data recorded in particular observation. Analysing these values is important as this may lead to weak or biased analysis.\n",
    "\n",
    "We can handle missing values in many ways:\n",
    "\n",
    "Delete:With dropna() method from Pandas library can be used to delete rows and columns , one can delete entire row by axis=0 or columns by axis=1\n",
    "\n",
    "df['Column_n'] = df['columns_n'].dropna(inplace=True, axis=0)\n",
    "\n",
    "df['Exterior2nd'] = df['Exterior2nd'].dropna(inplace=True, axis=0)\n",
    "Impute: Deleting data might cause huge amount of data loss, so replacing it might prove to be a better coption than deleting. For imputation of missing values one can use fillna() method and replace the missing values with mean, median of that particular column as per requirement.\n",
    "\n",
    "df['column_n']= df['column_n'].fillna(df['column_n'].mean(),inplace=True )\n",
    "\n",
    "df['FireplaceQu'] = df['FireplaceQu'].fillna(0,inplace=True )\n",
    "0 is used for the purpose of imputation because houses which don’t have fireplace are showing NaN values so it is logical to fill this with 0, for other variables central tendency can be used to fill null values.\n",
    "\n",
    "Predictive filling: Use interpolate() method is will perform a linear interpolation in order to fill missing values , it uses multiple methods to fill the missing values like linear, time, index, values, nearest, zero, etc\n",
    "\n",
    "df.interpolate(method ='linear', limit_direction ='forward')\n",
    "HeatMap\n",
    "We will generate heatmap of the output of isnull() in order to detect missing values\n",
    "\n",
    "sns.heatmap(df.isnull())\n",
    "plt.show()\n",
    "\n",
    "Null values heat map\n",
    "Correlation\n",
    "The correlation coefficient is a statistical measure of the strength of the relationship between the relative movements of two variables.\n",
    "\n",
    "In other words, when compare two variables , if one variable changes, how does this effect change in the other variable?\n",
    "\n",
    "The values range between -1.0 and 1.0. A correlation of -1.0 shows a perfect negative correlation, while a correlation of 1.0 shows a perfect positive correlation.\n",
    "A correlation of 0.0 shows no linear relationship between the movement of the two variables.\n",
    "For eg. smoking is known to be correlated with lung cancer. Since, smoking increases the chances of lung cancer.\n",
    "Correlation does not imply Causation\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "# df.corr() creates a correlation matrix \n",
    "corr_matrix = df.corr()\n",
    "# helps in creating a 0's matrix of df.corr() shape\n",
    "mask = np.zeros_like(corr_matrix)\n",
    "# Returns copy of array with lower part of the triangle\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    sns.heatmap(corr_matrix, mask=mask, square=True)\n",
    "\n",
    "Correlation heat map\n",
    "In our case due to too many variables in dataset it becomes difficult to visualise each variable we can also create a correlation matrix for the same and work on each variable independently for better analysis.\n",
    "\n",
    "\n",
    "Form the above plot we can see that GrLivArea and SalePrice has positive corelation (score of 0.70862) with each other while , in other words it tells us that with increase in size of GrLivArea the cost of house will increases\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.regplot(x='GrLivArea',y='SalePrice',data=df)\n",
    "\n",
    "The above plot shows the positive correlation between GeLivArea size and SalePrice.\n",
    "\n",
    "This was a brief introduction to Exploratory Data Analysis.\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
